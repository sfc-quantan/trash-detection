{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MNISTの数字分類\n",
    "# 参考: https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "\n",
    "def build_cnn(input_shape, nb_filters, filter_size, pool_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(nb_filters,\n",
    "                            filter_size[0], filter_size[1],\n",
    "                            border_mode='valid',\n",
    "                            input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(nb_filters, filter_size[0], filter_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_history(history, outdir):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['acc'], marker='.')\n",
    "    plt.plot(history.history['val_acc'], marker='.')\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(os.path.join(outdir, 'acc.png'))\n",
    "\n",
    "    # 損失の履歴をプロット\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], marker='.')\n",
    "    plt.plot(history.history['val_loss'], marker='.')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(os.path.join(outdir, 'loss.png'))\n",
    "\n",
    "\n",
    "def visualize_filter(model):\n",
    "    # 最初の畳み込み層の重みを取得\n",
    "    # tf => (nb_row, nb_col, nb_channel, nb_filter)\n",
    "    # th => (nb_filter, nb_channel, nb_row, nb_col)\n",
    "    W = model.layers[0].get_weights()[0]\n",
    "\n",
    "    # 次元を並べ替え\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        # (nb_filter, nb_channel, nb_row, nb_col)\n",
    "        W = W.transpose(3, 2, 0, 1)\n",
    "\n",
    "    nb_filter, nb_channel, nb_row, nb_col = W.shape\n",
    "\n",
    "    # 32個（手抜きで固定）のフィルタの重みを描画\n",
    "    plt.figure()\n",
    "    for i in range(nb_filters):\n",
    "        # フィルタの画像\n",
    "        im = W[i, 0]\n",
    "\n",
    "        # 重みを0-255のスケールに変換\n",
    "        scaler = MinMaxScaler(feature_range=(0, 255))\n",
    "        im = scaler.fit_transform(im)\n",
    "\n",
    "        plt.subplot(4, 8, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 128\n",
    "    nb_classes = 10\n",
    "    nb_epoch = 100\n",
    "\n",
    "    img_rows, img_cols = 28, 28\n",
    "    nb_filters = 32\n",
    "    filter_size = (5, 5)\n",
    "    pool_size = (2, 2)\n",
    "\n",
    "    # MNISTデータのロード\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # 画像集合を表す4次元テンソルに変形\n",
    "    # keras.jsonのimage_dim_orderingがthのときはチャネルが2次元目、tfのときはチャネルが4次元目にくる\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    # 画素を0.0-1.0の範囲に変換\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # one-hot-encoding\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "    # 畳み込みニューラルネットワークを構築\n",
    "    model = build_cnn(input_shape, nb_filters, filter_size, pool_size)\n",
    "\n",
    "    # モデルのサマリを表示\n",
    "    model.summary()\n",
    "    # モデルをコンパイル\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 学習前の1層目のフィルタを可視化\n",
    "    visualize_filter(model)\n",
    "\n",
    "    # Early-stopping\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    # モデルの訓練\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # 学習後の1層目のフィルタを可視化\n",
    "    visualize_filter(model)\n",
    "\n",
    "    # 学習履歴をプロット\n",
    "    plot_history(history, 'result_mnist')\n",
    "\n",
    "    # モデルの評価\n",
    "    loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    print('Test loss:', loss)\n",
    "    print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tf]",
   "language": "python",
   "name": "Python [tf]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
