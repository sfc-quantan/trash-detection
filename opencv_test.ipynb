{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/src/pyenv/versions/latest_mod/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator\n",
    "import matplotlib.pyplot as Plt\n",
    "import keras\n",
    "import gpu_config\n",
    "import tensorflow\n",
    "from keras import metrics\n",
    "from keras.models import Sequential,Model,load_model,model_from_json\n",
    "from keras.layers import Dense,Activation,Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import MaxPooling2D,Dropout\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "\n",
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.67519069,  0.68980581,  0.68904477,  0.6863631 ,  0.69041187,\n",
      "         0.68647474,  0.68765563,  0.68454581,  0.67709845,  0.67959517,\n",
      "         0.67967308,  0.67877322,  0.68284172,  0.68928415,  0.67761093,\n",
      "         0.6778658 ,  0.67086482,  0.68136966,  0.67946094,  0.67955726,\n",
      "         0.68064368,  0.68751889,  0.67484176,  0.68018204,  0.67508447,\n",
      "         0.6862027 ,  0.68880498,  0.68656582]], dtype=float32), array([[ 0.5110479 ,  0.49906981,  0.4905943 ,  0.48958546,  0.48982966,\n",
      "         0.48949733,  0.48944056]], dtype=float32)]\n",
      "(1, 28)\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0.5110479   0.49906981  0.4905943   0.48958546  0.48982966  0.48949733\n",
      "   0.48944056]]\n",
      "[585.6418, 213.578, 41.41776, 20.76343]\n",
      "[571.4471, 185.474, 17.45388, 27.44127]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k=929\n",
    "\n",
    "\n",
    "image = Image.open(\"1/\"+str(k)+\".jpg\")\n",
    "f=open(\"1/annotations/\"+str(k)+\".json\",\"r\")\n",
    "json_dict=json.load(f)\n",
    "#image=Plt.imread(\"1/122.jpg\")\n",
    "data = np.asarray(image, dtype=float)\n",
    "data = data.reshape(1,480,640,3)\n",
    "\n",
    "testdata=model.predict(data)\n",
    "print(testdata)\n",
    "test1=testdata[0]\n",
    "test2=testdata[1]\n",
    "test1=np.array(test1)\n",
    "test2=np.array(test2)\n",
    "print(test1.shape)\n",
    "\n",
    "test1=test1.reshape(7,4)\n",
    "\n",
    "for i in range(7):\n",
    "    test1[i][0]*640\n",
    "    test1[i][1]*480\n",
    "    test1[i][2]*300\n",
    "    test1[i][3]*300\n",
    "\n",
    "print(test1.astype('int32'))\n",
    "print(test2)\n",
    "for i in range(len(json_dict[\"objects\"])):\n",
    "    print(json_dict[\"objects\"][i][\"x_y_w_h\"])\n",
    "\n",
    "\n",
    "#input_shape = (width, height, 3)\n",
    "#data = np.load(\"testdata.npy\")\n",
    "#data = data.astype('float32')\n",
    "#testdata=model.predict(data)\n",
    "#testdata1=np.array(testdata[0])\n",
    "#testdata2=np.array(testdaa[1])\n",
    "#np.save(\"testxywh.npz\",testdata1)\n",
    "#np.save(\"testc.npz\",testdata2)\n",
    "\n",
    "\n",
    "input_shape = (480, 640, 3)\n",
    "data = np.load(\"testdata.npy\")\n",
    "data = data.astype('float32')\n",
    "testdata=model.predict(data)\n",
    "y_xywh=np.array(testdata[0])\n",
    "y_c=np.array(testdata[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.67519069  0.68980581  0.68904477  0.6863631 ]\n",
      "  [ 0.69041187  0.68647474  0.68765563  0.68454581]\n",
      "  [ 0.67709845  0.67959517  0.67967308  0.67877322]\n",
      "  ..., \n",
      "  [ 0.67086482  0.68136966  0.67946094  0.67955726]\n",
      "  [ 0.68064368  0.68751889  0.67484176  0.68018204]\n",
      "  [ 0.67508447  0.6862027   0.68880498  0.68656582]]\n",
      "\n",
      " [[ 0.67519069  0.68980581  0.68904477  0.6863631 ]\n",
      "  [ 0.69041187  0.68647474  0.68765563  0.68454581]\n",
      "  [ 0.67709845  0.67959517  0.67967308  0.67877322]\n",
      "  ..., \n",
      "  [ 0.67086482  0.68136966  0.67946094  0.67955726]\n",
      "  [ 0.68064368  0.68751889  0.67484176  0.68018204]\n",
      "  [ 0.67508447  0.6862027   0.68880498  0.68656582]]\n",
      "\n",
      " [[ 0.67519069  0.68980581  0.68904477  0.6863631 ]\n",
      "  [ 0.69041187  0.68647474  0.68765563  0.68454581]\n",
      "  [ 0.67709845  0.67959517  0.67967308  0.67877322]\n",
      "  ..., \n",
      "  [ 0.67086482  0.68136966  0.67946094  0.67955726]\n",
      "  [ 0.68064368  0.68751889  0.67484176  0.68018204]\n",
      "  [ 0.67508447  0.6862027   0.68880498  0.68656582]]\n",
      "\n",
      " ..., \n",
      " [[ 0.67519069  0.68980581  0.68904477  0.6863631 ]\n",
      "  [ 0.69041187  0.68647474  0.68765563  0.68454581]\n",
      "  [ 0.67709845  0.67959517  0.67967308  0.67877322]\n",
      "  ..., \n",
      "  [ 0.67086482  0.68136966  0.67946094  0.67955726]\n",
      "  [ 0.68064368  0.68751889  0.67484176  0.68018204]\n",
      "  [ 0.67508447  0.6862027   0.68880498  0.68656582]]\n",
      "\n",
      " [[ 0.67519069  0.68980581  0.68904477  0.6863631 ]\n",
      "  [ 0.69041187  0.68647474  0.68765563  0.68454581]\n",
      "  [ 0.67709845  0.67959517  0.67967308  0.67877322]\n",
      "  ..., \n",
      "  [ 0.67086482  0.68136966  0.67946094  0.67955726]\n",
      "  [ 0.68064368  0.68751889  0.67484176  0.68018204]\n",
      "  [ 0.67508447  0.6862027   0.68880498  0.68656582]]\n",
      "\n",
      " [[ 0.67519069  0.68980581  0.68904477  0.6863631 ]\n",
      "  [ 0.69041187  0.68647474  0.68765563  0.68454581]\n",
      "  [ 0.67709845  0.67959517  0.67967308  0.67877322]\n",
      "  ..., \n",
      "  [ 0.67086482  0.68136966  0.67946094  0.67955726]\n",
      "  [ 0.68064368  0.68751889  0.67484176  0.68018204]\n",
      "  [ 0.67508447  0.6862027   0.68880498  0.68656582]]]\n"
     ]
    }
   ],
   "source": [
    "y_xywh=y_xywh.reshape(y_xywh.shape[0],7,4)\n",
    "\n",
    "for i in range(y_xywh.shape[0]):\n",
    "    for j in range(y_xywh.shape[1]):\n",
    "        y_xywh[i][j][0]*640\n",
    "        y_xywh[i][j][1]*480\n",
    "        y_xywh[i][j][2]*300\n",
    "        y_xywh[i][j][3]*300\n",
    "\n",
    "\n",
    "print(y_xywh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_xywh=np.zeros(10570*28).reshape(10570,7,4)\n",
    "#y_xywh=np.random.rand(2000,7,4)*400\n",
    "#print(y_xywh[0])\n",
    "#y_c=np.zeros((10570*7)).reshape(10570,7)\n",
    "#y_c+=[1,1,0,0,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### cascade_path = \"/usr/local/opt/opencv/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml\"\n",
    "#cascade_path =\"/Users/quantan/workspace/model.h5\"\n",
    "#cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "color = (255, 255, 255)\n",
    "cap = cv2.VideoCapture(\"/home/quantan/notebooks/workspace/back_REC_161028_082112.avi\")\n",
    "count=0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()   \n",
    "    if(ret==False):\n",
    "        break\n",
    "    \n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #faces = cascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30, 30),flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    #cv2.rectangle(frame,tuple((int(x-(w/2)),int(y-(h/2)))),tuple((int(x+(w/2)),int(y+(h/2)))),color,thickness=2)\n",
    "\n",
    "\n",
    "    #if len(faces) != 0:\n",
    "    #検出した顔を囲む矩形の作成\n",
    "        #for rect in faces:\n",
    "            #print(tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]),print(rect))\n",
    "            #cv2.rectangle(frame, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), color, thickness=2)\n",
    "            #cv2.rectangle(frame,tuple((int(x-(w/2)),int(y-(h/2)))),tuple((int(x+(w/2)),int(y+(h/2)))),color,thickness=2)\n",
    "            \n",
    "    for i in range(y_c.shape[1]):\n",
    "        if(y_c[count][i]>0.5):\n",
    "            x,y,w,h=y_xywh[count][i][0],y_xywh[count][i][1],y_xywh[count][i][2],y_xywh[count][i][3]\n",
    "            \n",
    "            \n",
    "            #cv2.rectangle(frame,tuple((int(x-(w/2)),int(y-(h/2)))),tuple((int(x+(w/2)),int(y+(h/2)))),color,thickness=2)\n",
    "            cv2.rectangle(frame,tuple((int(x-(w/2)),int(y-(h/2)))),tuple((int(x+(w/2)),int(y+(h/2)))),color,thickness=2)\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    #cv2.imshow(\"hello\",frame)\n",
    "    #img = cv2.imread('/home/quantan/notebooks/workspace/result/result'+str(i)+'.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imwrite(\"result/result\"+str(count)+\".png\",frame)\n",
    "    count=1+count\n",
    "   \n",
    "    #code = cv2.waitKey(1)\n",
    "    #if code == ord(\"q\"):\n",
    "    if(count>1200):\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "video = cv2.VideoWriter('video.mp4', fourcc, 20.0, (640, 480))\n",
    "\n",
    "for i in range(1,1368):\n",
    "    \n",
    "    img = cv2.imread('/home/quantan/notebooks/keras-frcnn/results_imgs/'+str(i)+'.png')\n",
    "    \n",
    "    video.write(img)\n",
    "\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "LATEST",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
